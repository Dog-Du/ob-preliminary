join :
  join-tables刚看到的时候我是一头雾水，不知道怎么实现，但是慢慢思考之后才有了思路。
  把join-tables分成两部分看， select * from a inner join b on ********;
  把第一个inner join前面的当做一部分，把第一个inner join后面的当做一部分。
  第一个inner join前面的部分，相当于无条件join，第一个inner join后面相当于有条件join。
  where 部分是会下推的谓词，不会设计join的条件，换句话说，where在语法树上是在join下面的。

  parse:
  1.先支持inner join on关键字
  2.分割，分成 from a inner join b on condition
  3.在第一个inner join前面直接使用自带的join，因为没有条件限制，所以全部输出
  4.在之后的inner join，分成，左边的部分和当前的table，以condition连接。
  5.参考attr_list可写join_list
  6.写一个JoinSqlNode，放table_name和condition
  7.SelectSqlNode里放个vector<JoinSqlNode>记录所有的东西

  resolve:
  1.把joined_table都放进tables，但是多开一个unordered_set<Table *, ConditionSqlNode>
  2.在SelectStmt放进一个unordered_set，作为信息传递

  optimize:
  1.在JoinLogicalNode中，添加表达式表示是否是带条件的连接
  2.然后在生成的时候，对于inner join前面的，不进行修改，就是无条件连接
  3.在inner join后面的，进行修改，添加expression，表示有条件连接，并把连接的条件放进JoinLogicalNode中
  4.在JoinPhysicalNode中进行修改，也加一个expression

  execute:
  1.修改next部分代码，在连接之前判断是否能连接。

date :
  1.添加date关键字，有的做法是在下面过滤date类型，我原本也是这么做的，可以通过测试，
    但是会出现问题，因为date是chars的子集，所以会出现在chars字段中插入date时失败，因此完全放弃在词法分析阶段过滤date
  2.转化策略为“如果chars需要转化为date，则尝试进行转化，如果转化失败则报错”
  3.寻找需要转化的地方：
      有: filter_stmt,update_stmt
  4.不知道为什么这么做之后basic过不了了，我就没继续管
  5.需要写str_to_date的函数和date_to_str的函数，尤其是str_to_date的函数要小心写。
  6.date的保存我选择了unsigned int,也就是uint32_t，这是为了区别于int的同时保存4字节的大小。
  7.date的比较可以直接使用int的比较，检查date是否合理要仔细。
  8.需要考虑之后的处理，比如在 in 中： select * from t where a in ('2024-5-10', 0),
    我的处理是，在value部分处理，如果需要进行比较，那么尝试类型转化，转化失败则匹配失败

drop table:
  官方文档有讲解，一步一步照着来就写完了。
  我也忘了怎么写的了。

update :
  parse:
    update关键字已经有了，不需要在parse做过多的事情
  resolve:
    增加update_stmt，参考delete和insert的写法完成，因为要指示修改字段的位置
    我选择了非常丑陋的方式: 把修改字段的位置在这个阶段全部找到，然后进行保存.
    为什么保存字段的位置？因为update_operator在整棵树的最上端，而且并且整个树上不存在改变tuple中的schema的操作
      所以可放心这么做
  optimize:
    增加update_operator
    需要生成逻辑树和物理树，逻辑树也是把修改字段的位置和修改的value保存下来
    最后把这两个信息传递给物理算子这个时候算是完成了信息传递阶段
  execute:
    不需要做什么
  write:
    这个时候需要写算子，有了修改的值和修改的位置。我选择先删除原来的，然后在插入。
    插入tuple的方式可以看insert算子，删除可以看delete算子。
    但是出现了问题:
      如果delete的字段在where出现并且有index，那么会出错，原因在于在扫描b_plus_tree的时候上了读锁，再上写锁会abort
      我想了几个解决方法:
        1.不上读锁，但是需要更改大量代码，而且可能会在后面出问题，放弃
        2.先保存所有需要删除的字段，然后先全部扫描并保存record，扫描结束后，关闭b_plus_scanner，然后先删除再插入
        3.锁升级解决问题
        4.读论文

        所以我选择了2. ，其实2. 是多线程不安全的，以2PL的角度去看，这可能导致不可重复读。

    别人的方法似乎是在表中新增方法，update_record，但是这同样是没有考虑更新的字段有index并且where中出现的，
    而且所有的测试样例都没有涉及这一点，所以我觉得可能是个bug。

  多字段update:
    parse:
      需要新增update_list指示都更新了哪些字段，都更新成了哪些值。
      std::vector<std::string> std::vector<Value>
      需要注意的是: 这里需要参考rel_list那样，这是一个递归的，需要进行reverse。
      但是与rel_list不同的是，要考虑update不可为空。
    resolve,optimize,execute,write:
      其实和上面的一样，就是把多字段修改需要保存多个修改位置的下标而已。


aggregation-function:
  主要思路是：不把聚合函数当做函数，而是当做一种特殊的属性（比如：MIN(a)就是属性a上的某种特殊值），
      因为测试样例均为简单聚合，所以可以通过。
  parse:
    新增MAX,SUM,AVG,MIN,COUNT关键字，然后分别写这几个需要怎么做，然后放入rel_attr中。
    在RelAttrSqlNode新增AggregationType表示是否是agg，或者agg是什么类型。
    在parse_stage中对agg进行处理，判断是否全是agg或者全是rel_attr，不然则报错。
    需要注意点的一点是：虽然miniOB没有涉及，但是在空表中count(*)应该输出0，而count(a)应该无输出。
    换句话说count(*)会把null也 +1
  resolve:
    我在Field类中也新增了AggType，有一说一，这一点也不优雅，如果现在让我写，我肯定不会这么写，虽然不会优雅多少。
    然后在 SelectStmt::create 中的遍历，进行修改，把aggtype的信息塞进去，尤其是count(*)不像*，会把属性值变成一列，
    所以需要特殊处理。
    最后把select_stmt中fields填好，把agg的信息放进去。
  optimize:
    生成逻辑树阶段：
      先检查聚合是否合理，比如：在chars上SUM就显然不合理。
      然后新增一个aggregation_operator,把它放在project和filter中间(如果是聚合的话)

    生成物理树阶段：
      这个时候有了各个字段统计的聚合类型，因为agg需要完全读取数据之后才能得知结果。
      因为aggregation是pipeline breaker，同时Aggregation和null与group by密切相关
      因此建议在这个地方提前考虑这两者的处理方法。
      选择tuple：
        Aggregation的tuple需要两个特点：
          1.能够保存实际值（保存value）
          2.拥有关于字段的信息
        观察之后，发现rowtuple不行，因为Aggregation的tuple没有实际存在磁盘中，只会在内存中存在，没法存value。
        projetuple不行，因为projecttuple只是个壳子，没有实际存东西。
        ValueListTuple不行，因为没有存信息（不过可以配合std::vector<Field>）使用就好
        因此我自己写了一个AggregationTuple，长度和table中的一样，只是在各个字段增加了聚合类型。
  write:
    需要写算子，考虑到之后应该要写group by，所以建议写在next而不是open，即使它是pipeline breaker。
    第一次初始化发生在获得schema，这个时候对count_stat 和 count类型进行初始化。
    拿到第一个tuple后进行第二次初始化，如果是一个空表，即一个tuple也没有，则直接返回
    如果不是空表则第二次初始化，初始化内容为 : 把MIN，MAX，SUM，AVG赋值成第一个tuple对应的值，COUNT + 1 (如果不为null)
    然后每获得一个tuple就进行一次修改
    在最后，对AVG进行操作，除以个数（如果个数为0，则变成null）。
    如果在这里考虑NULL的话：应该在各个字段增加一个count，表示非null的个数，最后再根据个数来判断最终类型，比如AVG，SUM，MIN在count=0的时候变成null

    关于group by的想法（还没写）；首先可以在RC中新增一个返回值，表示分组，如果在Aggregation中新增一个bool值表示一段的结束。
    这样应该可以处理group by。

like：
  like很简单，可能唯一难得地方就在于模式串的匹配那个部分。
  思路：
    新增关键字like，把like当做一个comp_op比较运算符，放在comp_op部分。
    在ComparionExpression的枚举部分新增like枚举，然后新增匹配函数，如果匹配成功则返回true即可。
  关于模式串的匹配：
    本来以为是双指针就行，然后后来被一个样例打败： pipineapple 和 %e 因为双指针实际上是一个贪心，
      在pipine哪里看到e之后会直接匹配，导致后面没有匹配上,换句话说，这个匹配应该是比较宽松的匹配。
    所以正确答案是dp.只不过dp效率远低于双指针，双指针是 O(n + m)，dp是 O(n * m) 有一说一，差的有点远。


simple-sub-query:
  要支持 in和exists ，只会出现在where中。既继续支持子查询又需要支持常量集合(形如：(2,3,4,"abc"))
  思路：
    因为只会在where子句中出现，所以把子查询当做条件处理，把in和exists当做比较运算符。
    怎么统一处理子查询和常量集合？ 我的方法是用一个 PipeLineBreaker 算子作为过渡。
    这个算子的作用是：在open阶段获得所有需要的tuple，在next中依次遍历。因为这个算子的行为是非常明确的，
        因此也方便在expression中用于比较

    然后问题是怎么把select子句塞进filter中？我的方法是把physical算子塞进expression中，
    之后再open阶段依次调用expression中的open。
    这个时候会有一个这样的问题：考虑这样的select， select * from t where a=(select max(a) from t)
    问题在于一个select中出现了两次表 t， 考虑到select是一个只读操作，这样应该是可以允许的，我在mysql进行尝试，
    确实可以运行，然后考虑之后有一个题目是update-select，update是写操作，select是读操作
    于是： update t set a=(select max(a) from t) where 1=1 这样应该是不允许的，实际上mysql也确实不允许
    这个时候需要注意的就是open时候的顺序，保证expression是第一个被open的。

  parse：
    先支持exists和in关键字，然后在condition中添加select_stmt和value_list两种，一个代表子查询，一个代表常量集合。
    因为exists其实相当于一个单目运算符，但为了方便处理，可以考虑仍然使用comprisionexpr，只是left或者right有一个不填罢了。
    只需要用compop进行区别即可，同时需要注意 常量集合和子查询 虽然都是返回的tuple的集合，但是应该进行区分。

  resolve：
    很自然的，既然把子查询放在expression中，那么应该去修改filter_stmt而select_stmt不需要修改。
    在filter_unit中增加一个select_stmt和value_list即可，用于之后生成算子。
  optimize：
    可以自己写个expression表示sub查询，因为expression在存储的时候有std::vector<std::unique_ptr<Expression>>，
    所以只要新expression继承expression就可以放心的使用。在生成物理执行计划的时候别忘了用pipelinebreaker就行。
  execute：
    没有需要修改的地方
  算子部分：
    需要写一个算子，它在树上的位置位于子查询和主查询之间充当过渡。同时修改所有需要filter的算子，在open期间，先open表达式。
    主要就是 table_get_physical_operator 和 predicate_physical_operator。
    然后就可以快乐运行了。

  有三个注意点：
    1.如果在运行算子期间需要返回failure怎么办？
      我的方法有两个：
        1) 先运行后打印，原本的输出部分是边next边向缓冲池写入，可以修改为先用一个vector存储所有结果tuple，
            期间出现问题直接failure即可，最后没问题了再一起写入。
        2) 修改缓冲池，如果出现问题，把之前写入的部分在形式上删去。

        就思路来说 2) 更清晰，但是就实现的难度来说其实 1) 更简单因为实现2)是需要去读缓冲池部分的代码的(虽然不长就是了)，
          效率方面的话，感觉是 1) 会差一些。
        我选择了2)，先统计写入了多少，然后在失败的时候进行回溯即可。
        需要注意的是环形缓冲池类似一个循环队列，write_data就是back，data_size就是front，这样就很好用这部分的代码了。

    2.头文件包含导致类之间相互依赖怎么办？
      其实只要在.h文件先声明类，然后在.cpp文件中直接包含头文件使用就好了。
      头文件相互依赖管我实现代码什么事(bushi -> 其实是编译的问题，头文件不能出现相互依赖，但是.cpp可以随便添加.h文件。
        这又暴露出我对编译阶段到底做了什么还是有些不甚了解。
    3.这么做的几个缺点：
      首先是，生成逻辑树之后，因为子查询位于expression中，所以在optimize中的rewrite和optimize不会涉及查询，
        也就是子查询不会参与优化阶段。
      齐次是，这么做在多线程下可能会出问题（2PL角度），隔离等级应该会降到不可重复读
        （即，select * from t where a in (select * from t) 中两次查询表t的结果可能不同）
        但是以MVCC角度来看似乎又没有问题。哎，我的理论太差了，这一两月应该要找一些理论方面的知识学习一下。
      最后是，空间上的问题，因为PipeLineBreaker是字面意义上的火山模型破坏者，对于内存不太优化，当然这样可以避免反复读磁盘。


multi-index:
  额，骗过去的。其实没实现对应功能。主要是我不清楚multi-index到底有啥用（目移）
  骗的方法是：
    先在语法上支持multi-index,然后实际运行时。
    只以第一个字段建立索引即可，这样就能骗过去（）。

unique:
  呃呃，也是骗过去的。不过这个算是完成对应功能了。
  骗的方法是：
    先在语法上支持unique，实际运行时，先检查index里面有没有相同的
    然后如果有，则不插入，返回错误信息即可。
  需要在index_meta添加一条信息，is_unique，bool值。
  然后在to_json和from_json时，添加is_unique，这样就实现了is_unique信息的持久化。
  unique就可以骗过去了。

update_select:
  这个不是骗的，思路类似于simple-sub-quey，只是把子查询从where移到了set哪里。
  同时，增加一个结构体，把子查询和常量放在一起，如果子查询为空，就说明是常量输入。
  然后在update-physical-operator中新增一个判断。
  需要注意的点：
    1.如果子查询结果为空，相当于置为NULL，需要注意判断对应列能否为NULL
    2.子查询结果是否为多行，多行则返回错误信息
    3.子查询如果为多列，返回错误信息。
    4.如果需要update的行数为0个，那么即使子查询有上面三个错误也返回success
      （这个我卡了好久，一直没发现哪里错了，后来猜想可能是这里错了，然后MySQL尝试之后还真是。）
    5.注意类型转化，会出现在CHARS里面插入INT类型。

order-by、big-order-by:
  order-by在语法树上应该是聚合之上，投影之下。
  因为后面group-by需要考虑，group-by的位置应该是在聚合之下，谓词之上

  我实现的order-by是pipelinebreaker，先得到所有tuple，然后用std::sort+自定义排序函数进行排序。

  当然，需要在语法树先支持order by。然后获得排序字段以及升序降序的信息。
  在select_stmt阶段，解析排序字段，然后得到排序字段的下标已经升序降序信息。
  因为会有表的连接，所以这里需要注意，下标 = 前面几个表的field_num + 在该表下标位置。
  比较函数：遍历排序字段，出现的顺序就是优先级。
  需要先判断是否是null。
  可以选择把order-by哪里选择用comparisonexpr，比较方便。

  当然效率一般，对比了一下，大概是1W的数据量，我的代码从输入sql到完全输出大概需要6s，而MySQL只需要不到2s。
  薄纱，甚至我的内存还有泄露().....

null :
  首先，需要在表中记录下来各个列的可空否nullable。
    方法是在fieldmeta中新增nullable，bool值，然后在to_json和from_json中新增nullable。
    实现了field的nullable的可持久化。
  齐次，支持null关键词，和not关键字。
    先实现创建table的时候的nullable，默认是可为空的，行为可参考MySQL
    完成table的创建
  最后，实现值的null。
    我的方法是Value的类型增加NULLS，同时添加一个字节用来表示nullable。
    num_value_中新增char is_null_[5]，每一个value的大小都增加了1字节。
    对于str_value_如果是chars，那么把str_value[0]用来表示是否为空。

    一个value的字节流就是包含了null的信息的字节流了。
    但是chars和非chars的保存nullable的位置不同,chars在字节流头部，非chars在字节流尾部。
    所以，一个value置为null需要把is_null_[5]的首和尾均置为true同时清空str_value_。
    之后就是关于Value的部分细节的调整，还需要在compare进行调整，NULL和任何值进行比较都是小于。
    如果比较两者中有NULL，则返回一个非法值，比如 2，建议把比较的结果设置成CompareResult枚举类型
    在index中也需要修改对应修改，需要特判NULL。

    当然，在聚合，condition，update，等等地方都需要注意NULL。

    还需要支持IS，IS NOT来判断NULL。
    在子查询中，IN和NOT IN相当于是用=进行比较，所以NULL都会返回false。

  有的方法不是在Value中放null，而是在sys_field中记录对应是否是空。
  这样应该可以占用空间更少，但是实现更复杂更麻烦。

  还有一件事，实现的方法一定要保证Value的字节流（data）返回的值
  一定是一次性返回整个字节流，能够根据字节流还原。







